{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Importing necessary libraries and packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoToPostgresELT:\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Initialize Environment Variables and Database Connection\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the MongoToPostgresETL class.\n",
    "        Loads environment variables and sets up MongoDB and PostgreSQL connection parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        # Load environment variables from .env file\n",
    "        load_dotenv()\n",
    "\n",
    "        self.mongo_url = os.getenv(\"MONGO_DB_URL\")\n",
    "        self.mongo_db_database_name = os.getenv(\"MONGODB_DB_NAME\")\n",
    "        self.mongo_client = MongoClient(self.mongo_url)\n",
    "        self.db = self.mongo_client[\n",
    "            self.mongo_db_database_name\n",
    "        ]  # Initialize the database here\n",
    "\n",
    "        # PostgreSQL connection parameters from .env\n",
    "        self.pg_host = os.getenv(\"PG_HOST\")\n",
    "        self.pg_database = os.getenv(\"PG_DATABASE\")\n",
    "        self.pg_user = os.getenv(\"PG_USER\")\n",
    "        self.pg_password = os.getenv(\"PG_PASSWORD\")\n",
    "        self.pg_port = os.getenv(\"PG_PORT\")\n",
    "        self.pg_connection = None\n",
    "\n",
    "    def get_mongo_client(self) -> MongoClient:\n",
    "        \"\"\"\n",
    "        Establishes and returns a MongoDB client connection.\n",
    "\n",
    "        Returns:\n",
    "        MongoClient: MongoDB client instance.\"\"\"\n",
    "\n",
    "        if self.mongo_client is None:\n",
    "            self.mongo_client = MongoClient(self.mongo_url)\n",
    "        return self.mongo_client\n",
    "\n",
    "    def connect_to_postgres(self):\n",
    "        \"\"\"\n",
    "        Establish a connection to the PostgreSQL database.\n",
    "\n",
    "        Returns:\n",
    "        connection: A connection object to the PostgreSQL database.\"\"\"\n",
    "\n",
    "        try:\n",
    "            connection = psycopg2.connect(\n",
    "                dbname=os.getenv(\"PG_DATABASE\"),\n",
    "                user=os.getenv(\"PG_USER\"),\n",
    "                password=os.getenv(\"PG_PASSWORD\"),\n",
    "                host=os.getenv(\"PG_HOST\"),\n",
    "                port=os.getenv(\"PG_PORT\"),\n",
    "            )\n",
    "            print(\"Connection to PostgreSQL established successfully.\")\n",
    "            return connection\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to connect to PostgreSQL: {e}\")\n",
    "            return None\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # load callection as dataframe to work on them as required.\n",
    "\n",
    "    def load_collection_as_dataframe(self, collection_name: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Converts a MongoDB collection into a pandas DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        collection_name (str): The name of the MongoDB collection.\n",
    "        db_name (str): The MongoDB database name.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A DataFrame containing the MongoDB collection data.\"\"\"\n",
    "\n",
    "        client = self.get_mongo_client()\n",
    "        db = client[self.mongo_db_database_name]\n",
    "        collection = db[collection_name]\n",
    "        data = list(collection.find())\n",
    "\n",
    "        # Convert the data to a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Check if '_id' column exists and drop it if it does\n",
    "        if \"_id\" in df.columns:\n",
    "            df = df.drop(columns=[\"_id\"])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def load_dataframe_to_postgres(\n",
    "        self, df: pd.DataFrame, table_name: str, json_columns: list = []\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Writes a pandas DataFrame to a PostgreSQL table, with support for JSON fields.\n",
    "\n",
    "        Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to be written to PostgreSQL.\n",
    "        table_name (str): The name of the PostgreSQL table where data will be inserted.\n",
    "        json_columns (list): List of column names in the DataFrame that contain JSON data.\n",
    "                            These columns will be converted to JSON strings and cast to 'jsonb' in PostgreSQL.\n",
    "        \"\"\"\n",
    "        # Establish connection for this operation\n",
    "        connection = self.connect_to_postgres()  # Always establish a new connection\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Handle conversion of specified columns to JSON strings\n",
    "        for column in json_columns:\n",
    "            df[column] = df[column].apply(json.dumps)\n",
    "\n",
    "        # Prepare the columns and placeholders for SQL query\n",
    "        columns = df.columns.tolist()\n",
    "\n",
    "        # Create SQL query for insertion, casting JSON columns to jsonb\n",
    "        insert_query = sql.SQL(\n",
    "            \"\"\"\n",
    "            INSERT INTO {} ({}) \n",
    "            VALUES ({})\"\"\"\n",
    "        ).format(\n",
    "            sql.Identifier(table_name),\n",
    "            sql.SQL(\", \").join(map(sql.Identifier, columns)),\n",
    "            sql.SQL(\", \").join(\n",
    "                sql.SQL(\"%s::jsonb\") if col in json_columns else sql.Placeholder()\n",
    "                for col in columns\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Convert DataFrame rows to tuples\n",
    "        data_tuples = [tuple(row) for row in df.itertuples(index=False)]\n",
    "\n",
    "        try:\n",
    "            # Execute the insertion query\n",
    "            cursor.executemany(insert_query, data_tuples)\n",
    "            connection.commit()\n",
    "            print(f\"Data successfully loaded into {table_name} table.\")\n",
    "        except Exception as error:\n",
    "            print(f\"Error inserting data into PostgreSQL: {error}\")\n",
    "            connection.rollback()\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # function to perfrom full load and incremental load\n",
    "\n",
    "    def perform_full_load(self, dataframes: dict):\n",
    "        \"\"\"\n",
    "        Loads all DataFrames from the provided dictionary into corresponding PostgreSQL tables.\n",
    "\n",
    "        Parameters:\n",
    "        dataframes (dict): A dictionary where keys are DataFrame names (e.g., 'customers__df')\n",
    "                           and values are the corresponding pandas DataFrames.\"\"\"\n",
    "\n",
    "        for df_name, df in dataframes.items():\n",
    "            table_name = df_name.replace(\n",
    "                \"__df\", \"\"\n",
    "            )  # Remove '__df' to get the table name\n",
    "\n",
    "            # Determine if any JSON columns need special handling\n",
    "            json_columns = (\n",
    "                []\n",
    "            )  # Define any specific columns that are JSON formatted if needed\n",
    "\n",
    "            # Check for JSON columns in the DataFrame\n",
    "            if \"new_loan_terms\" in df.columns or \"restructure_terms\" in df.columns:\n",
    "                json_columns = [\n",
    "                    \"new_loan_terms\",\n",
    "                    \"restructure_terms\",\n",
    "                ]  # Adjust based on your DataFrame structure\n",
    "\n",
    "            try:\n",
    "                self.load_dataframe_to_postgres(\n",
    "                    df, f\"tbl_{table_name}\", json_columns=json_columns\n",
    "                )  # Call the loading function\n",
    "                print(f\"Successfully loaded data into table: tbl_{table_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading data into table {table_name}: {e}\")\n",
    "\n",
    "    def incremental_load(\n",
    "        self,\n",
    "        old_dataframe: pd.DataFrame,\n",
    "        collection_name: str,\n",
    "        table_name: str,\n",
    "        load_type: str,\n",
    "        added_at_col: str = \"added_at\",\n",
    "        modified_at_col: str = \"modified_at\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Performs an incremental load of data from a MongoDB collection to a PostgreSQL table.\n",
    "\n",
    "        Parameters:\n",
    "        collection_name (str): The name of the MongoDB collection to load data from.\n",
    "        table_name (str): The name of the PostgreSQL table to load data into.\n",
    "        load_type (str): The type of load operation ('insertion' or 'updation').\n",
    "        added_at_col (str): The name of the column used for new records.\n",
    "        modified_at_col (str): The name of the column used for updated records.\"\"\"\n",
    "\n",
    "        # Mapping of table names to their unique identifier columns\n",
    "        unique_id_mapping = {\n",
    "            \"tbl_customers\": \"customer_id\",\n",
    "            \"tbl_loan_types\": \"loan_type_id\",\n",
    "            \"tbl_loan_applications\": \"loan_id\",\n",
    "            \"tbl_loan_repayments\": \"repayment_id\",\n",
    "            \"tbl_loan_history\": \"history_id\",\n",
    "            \"tbl_loan_collateral\": \"collateral_id\",\n",
    "            \"tbl_loan_restructuring\": \"restructuring_id\",\n",
    "            \"tbl_loan_disbursements\": \"disbursement_id\",\n",
    "        }\n",
    "\n",
    "        # Determine last loaded state\n",
    "        old_load_last_state = old_dataframe[added_at_col].max()\n",
    "        old_update_last_state = old_dataframe[modified_at_col].max()\n",
    "\n",
    "        # # Fetch the latest DataFrame from the MongoDB collection\n",
    "        df = self.load_collection_as_dataframe(collection_name)\n",
    "\n",
    "        if load_type == \"insertion\":\n",
    "            #     for new records\n",
    "            new_records = df[df[added_at_col] > old_load_last_state]\n",
    "            print(new_records)\n",
    "            if not new_records.empty:\n",
    "                self.load_dataframe_to_postgres(new_records, table_name)\n",
    "\n",
    "        elif load_type == \"updation\":\n",
    "            # Filter for updated records\n",
    "            updated_records = df[df[modified_at_col] > old_update_last_state]\n",
    "            if not updated_records.empty:\n",
    "                unique_id_col = unique_id_mapping.get(table_name)\n",
    "                if unique_id_col is None:\n",
    "                    print(f\"No unique identifier mapping found for table: {table_name}\")\n",
    "                    return\n",
    "\n",
    "                for index, row in updated_records.iterrows():\n",
    "                    self.update_record_in_postgres(row, table_name, unique_id_col)\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "    # Function to Normalize tables and load into their repspective tables\n",
    "\n",
    "    def normalize_nested_fields(\n",
    "        self, df: pd.DataFrame, table_name: str, nested_fields: dict\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Normalizes nested fields in a DataFrame and inserts data into PostgreSQL.\n",
    "\n",
    "        Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing data with nested fields.\n",
    "        table_name (str): The name of the main PostgreSQL table.\n",
    "        nested_fields (dict): A dictionary where keys are nested fields in df,\n",
    "                            and values are the corresponding table names in PostgreSQL.\n",
    "        \"\"\"\n",
    "        # Iterate over each nested field\n",
    "        for nested_field, nested_table_name in nested_fields.items():\n",
    "            if nested_field in df.columns:\n",
    "                # Normalize the nested field into a separate DataFrame\n",
    "                nested_df = pd.json_normalize(df[nested_field])\n",
    "                nested_df.columns = [\n",
    "                    col.replace(\".\", \"_\") for col in nested_df.columns\n",
    "                ]  # Flatten column names\n",
    "\n",
    "                # Add unique IDs for the nested records\n",
    "                nested_df[f\"{nested_table_name}_id\"] = range(1, len(nested_df) + 1)\n",
    "\n",
    "                # Merge the IDs back to the main DataFrame\n",
    "                df = df.join(nested_df[f\"{nested_table_name}_id\"])\n",
    "\n",
    "                # Insert nested data into its respective table\n",
    "                self.load_dataframe_to_postgres(nested_df, nested_table_name)\n",
    "\n",
    "                # Drop original nested column from main DataFrame\n",
    "                df = df.drop(columns=[nested_field])\n",
    "\n",
    "        # Insert the main table with foreign keys for the nested tables\n",
    "        self.load_dataframe_to_postgres(df, table_name)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Helper Function to for insertion and updation into MongoDB\n",
    "\n",
    "    def insert_document(self, collection_name: str, document: dict):\n",
    "        \"\"\"\n",
    "        Inserts a document into the specified MongoDB collection only if\n",
    "        a document with the same unique identifier does not already exist.\n",
    "\n",
    "        Parameters:\n",
    "        collection_name (str): The name of the MongoDB collection.\n",
    "        document (dict): The document to insert into the collection.\n",
    "        \"\"\"\n",
    "\n",
    "        unique_id_mapping = {\n",
    "            \"customers\": \"customer_id\",\n",
    "            \"loan_types\": \"loan_type_id\",\n",
    "            \"loan_applications\": \"loan_id\",\n",
    "            \"loan_repayments\": \"repayment_id\",\n",
    "            \"loan_history\": \"history_id\",\n",
    "            \"loan_collateral\": \"collateral_id\",\n",
    "            \"loan_restructuring\": \"restructuring_id\",\n",
    "            \"loan_disbursements\": \"disbursement_id\",\n",
    "        }\n",
    "\n",
    "        # Ensure collection has a mapped unique identifier\n",
    "        unique_id_field = unique_id_mapping.get(collection_name)\n",
    "        if unique_id_field is None:\n",
    "            print(\n",
    "                f\"No unique identifier mapping found for collection '{collection_name}'. Document not inserted.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # Connect to collection\n",
    "        collection = self.db[collection_name]\n",
    "\n",
    "        # Check for existence of the document by unique identifier\n",
    "        if unique_id_field in document:\n",
    "            existing_doc = collection.find_one(\n",
    "                {unique_id_field: document[unique_id_field]}\n",
    "            )\n",
    "            if existing_doc:\n",
    "                print(\n",
    "                    f\"Document with {unique_id_field} = {document[unique_id_field]} already exists in collection '{collection_name}'.\"\n",
    "                )\n",
    "                return\n",
    "\n",
    "        # Insert the document if unique identifier check passes\n",
    "        result = collection.insert_one(document)\n",
    "        print(f\"Document inserted with ID: {result.inserted_id}\")\n",
    "\n",
    "    def update_document(self, collection_name: str, query: dict, update: dict):\n",
    "        \"\"\"\n",
    "        Updates an existing document in the specified MongoDB collection.\n",
    "\n",
    "        Parameters:\n",
    "        collection_name (str): The name of the MongoDB collection.\n",
    "        query (dict): The query to identify the document to update.\n",
    "        update (dict): The updates to apply to the document.\"\"\"\n",
    "\n",
    "        collection = self.db[collection_name]\n",
    "        result = collection.update_one(query, {\"$set\": update})\n",
    "        if result.matched_count > 0:\n",
    "            print(f\"Document updated: {result.modified_count} document(s) modified.\")\n",
    "        else:\n",
    "            print(\"No document found matching the query.\")\n",
    "\n",
    "    def update_record_in_postgres(\n",
    "        self, record: pd.Series, table_name: str, unique_id_col: str\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Updates an existing record in the PostgreSQL table based on a unique identifier.\n",
    "\n",
    "        Parameters:\n",
    "        record (pd.Series): The record to update.\n",
    "        table_name (str): The name of the PostgreSQL table to update.\n",
    "        unique_id_col (str): The name of the unique identifier column used for the update.\n",
    "        \"\"\"\n",
    "\n",
    "        # Establish connection for this operation\n",
    "        connection = self.connect_to_postgres()\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Prepare the SQL UPDATE statement\n",
    "        set_clause = \", \".join(\n",
    "            [f\"{col} = %s\" for col in record.index if col != unique_id_col]\n",
    "        )  # Exclude unique identifier\n",
    "        update_query = f\"\"\"\n",
    "            UPDATE {table_name} \n",
    "            SET {set_clause} \n",
    "            WHERE {unique_id_col} = %s\n",
    "        \"\"\"\n",
    "\n",
    "        # Values to be updated\n",
    "        values = tuple(record[col] for col in record.index if col != unique_id_col) + (\n",
    "            record[unique_id_col],\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # Execute the update query\n",
    "            cursor.execute(update_query, values)\n",
    "            connection.commit()\n",
    "            print(\n",
    "                f\"Record with {unique_id_col} {record[unique_id_col]} updated successfully.\"\n",
    "            )\n",
    "        except Exception as error:\n",
    "            print(f\"Error updating record in PostgreSQL: {error}\")\n",
    "            connection.rollback()\n",
    "        finally:\n",
    "            cursor.close()\n",
    "            connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "elt = MongoToPostgresELT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of MongoDB collections\n",
    "collections = [\n",
    "    \"customers\",\n",
    "    \"loan_types\",\n",
    "    \"loan_applications\",\n",
    "    \"loan_repayments\",\n",
    "    \"loan_history\",\n",
    "    \"loan_collateral\",\n",
    "    \"loan_restructuring\",\n",
    "    \"loan_disbursements\",\n",
    "]\n",
    "\n",
    "# Dictionary to hold DataFrames\n",
    "collections_dict = {}\n",
    "\n",
    "# Loop through each collection name and load it into a DataFrame\n",
    "for collection in collections:\n",
    "    df_name = f\"{collection}\"  # Create a dynamic variable name\n",
    "    collections_dict[df_name] = elt.load_collection_as_dataframe(\n",
    "        collection\n",
    "    )  # Load DataFrame\n",
    "\n",
    "# Accessing the DataFrames\n",
    "customers__df = collections_dict[\"customers\"]\n",
    "loan_types__df = collections_dict[\"loan_types\"]\n",
    "loan_applications__df = collections_dict[\"loan_applications\"]\n",
    "loan_repayments__df = collections_dict[\"loan_repayments\"]\n",
    "loan_history__df = collections_dict[\"loan_history\"]\n",
    "loan_collateral__df = collections_dict[\"loan_collateral\"]\n",
    "loan_restructuring__df = collections_dict[\"loan_restructuring\"]\n",
    "loan_disbursements__df = collections_dict[\"loan_disbursements\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restructuring_id</th>\n",
       "      <th>loan_id</th>\n",
       "      <th>new_loan_terms</th>\n",
       "      <th>restructure_terms</th>\n",
       "      <th>added_at</th>\n",
       "      <th>modified_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>445645329959805120</td>\n",
       "      <td>663194010682136064</td>\n",
       "      <td>{'interest_rate': 5, 'repayment_period_in_mont...</td>\n",
       "      <td>{'reason': 'Financial difficulties', 'new_sche...</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>2024-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>618227701498760192</td>\n",
       "      <td>919140988712724352</td>\n",
       "      <td>{'interest_rate': 3, 'repayment_period_in_mont...</td>\n",
       "      <td>{'reason': 'Unexpected expenses', 'new_schedul...</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>2024-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189098082925672288</td>\n",
       "      <td>535611310051475456</td>\n",
       "      <td>{'interest_rate': 4, 'repayment_period_in_mont...</td>\n",
       "      <td>{'reason': 'Unexpected expenses', 'new_schedul...</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>2024-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>477779993814011008</td>\n",
       "      <td>863687840789048960</td>\n",
       "      <td>{'interest_rate': 4, 'repayment_period_in_mont...</td>\n",
       "      <td>{'reason': 'Interest rate reduction', 'new_sch...</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>2024-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>620276799861859456</td>\n",
       "      <td>375253958161880512</td>\n",
       "      <td>{'interest_rate': 4, 'repayment_period_in_mont...</td>\n",
       "      <td>{'reason': 'Interest rate reduction', 'new_sch...</td>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>2024-10-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     restructuring_id             loan_id  \\\n",
       "0  445645329959805120  663194010682136064   \n",
       "1  618227701498760192  919140988712724352   \n",
       "2  189098082925672288  535611310051475456   \n",
       "3  477779993814011008  863687840789048960   \n",
       "4  620276799861859456  375253958161880512   \n",
       "\n",
       "                                      new_loan_terms  \\\n",
       "0  {'interest_rate': 5, 'repayment_period_in_mont...   \n",
       "1  {'interest_rate': 3, 'repayment_period_in_mont...   \n",
       "2  {'interest_rate': 4, 'repayment_period_in_mont...   \n",
       "3  {'interest_rate': 4, 'repayment_period_in_mont...   \n",
       "4  {'interest_rate': 4, 'repayment_period_in_mont...   \n",
       "\n",
       "                                   restructure_terms   added_at modified_at  \n",
       "0  {'reason': 'Financial difficulties', 'new_sche... 2024-10-24  2024-10-24  \n",
       "1  {'reason': 'Unexpected expenses', 'new_schedul... 2024-10-24  2024-10-24  \n",
       "2  {'reason': 'Unexpected expenses', 'new_schedul... 2024-10-24  2024-10-24  \n",
       "3  {'reason': 'Interest rate reduction', 'new_sch... 2024-10-24  2024-10-24  \n",
       "4  {'reason': 'Interest rate reduction', 'new_sch... 2024-10-24  2024-10-24  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_restructuring__df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to PostgreSQL established successfully.\n",
      "Data successfully loaded into tbl_customers table.\n",
      "Successfully loaded data into table: tbl_customers\n",
      "Connection to PostgreSQL established successfully.\n",
      "Data successfully loaded into tbl_loan_types table.\n",
      "Successfully loaded data into table: tbl_loan_types\n",
      "Connection to PostgreSQL established successfully.\n",
      "Data successfully loaded into tbl_loan_applications table.\n",
      "Successfully loaded data into table: tbl_loan_applications\n",
      "Connection to PostgreSQL established successfully.\n",
      "Data successfully loaded into tbl_loan_repayments table.\n",
      "Successfully loaded data into table: tbl_loan_repayments\n",
      "Connection to PostgreSQL established successfully.\n",
      "Data successfully loaded into tbl_loan_history table.\n",
      "Successfully loaded data into table: tbl_loan_history\n",
      "Connection to PostgreSQL established successfully.\n",
      "Data successfully loaded into tbl_loan_collateral table.\n",
      "Successfully loaded data into table: tbl_loan_collateral\n",
      "Connection to PostgreSQL established successfully.\n",
      "Data successfully loaded into tbl_loan_restructuring table.\n",
      "Successfully loaded data into table: tbl_loan_restructuring\n",
      "Connection to PostgreSQL established successfully.\n",
      "Data successfully loaded into tbl_loan_disbursements table.\n",
      "Successfully loaded data into table: tbl_loan_disbursements\n"
     ]
    }
   ],
   "source": [
    "elt.perform_full_load(collections_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document inserted with ID: 671b33052389b0eb19c29cb0\n"
     ]
    }
   ],
   "source": [
    "document = {\n",
    "    \"customer_id\": 619387217110,\n",
    "    \"first_name\": \"Ashlan\",\n",
    "    \"last_name\": \"Birdall\",\n",
    "    \"gender\": \"Female\",\n",
    "    \"age\": 78,\n",
    "    \"employment_status\": \"unemployed\",\n",
    "    \"income_level\": \"high\",\n",
    "    \"location\": \"Indianapolis\",\n",
    "    \"joined_date\": \"2018-09-11\",\n",
    "}\n",
    "\n",
    "\"\"\" \n",
    "- This function will insert a document into the customers collection into the MongoDB.\n",
    "- This also be added by adding can also be achieved using the MongDB compass. \n",
    "- But we decided to do this programmatically in order to avoid switching from different environment.\"\"\"\n",
    "\n",
    "elt.insert_document(\"customers\", document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       customer_id first_name   last_name  gender  age employment_status  \\\n",
      "6000  569676395005      Becka  Wennington  Female   45          employed   \n",
      "\n",
      "     income_level       location joined_date                added_at  \\\n",
      "6000          low  New York City  2018-09-01 2024-10-25 00:53:40.161   \n",
      "\n",
      "                 modified_at  \n",
      "6000 2024-10-25 00:53:40.161  \n",
      "Connection to PostgreSQL established successfully.\n",
      "Data successfully loaded into tbl_customers table.\n"
     ]
    }
   ],
   "source": [
    "elt.incremental_load(customers__df, \"customers\", \"tbl_customers\", \"insertion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document updated: 1 document(s) modified.\n"
     ]
    }
   ],
   "source": [
    "elt.update_document(\n",
    "    \"customers\", {\"customer_id\": 569676395005}, {\"income_level\": \"high\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to PostgreSQL established successfully.\n",
      "Record with customer_id 569676395005 updated successfully.\n"
     ]
    }
   ],
   "source": [
    "elt.incremental_load(customers__df, \"customers\", \"tbl_customers\", \"updation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restructuring_id</th>\n",
       "      <th>loan_id</th>\n",
       "      <th>new_loan_terms</th>\n",
       "      <th>restructure_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>445645329959805120</td>\n",
       "      <td>663194010682136064</td>\n",
       "      <td>{\"interest_rate\": 5, \"repayment_period_in_mont...</td>\n",
       "      <td>{\"reason\": \"Financial difficulties\", \"new_sche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>618227701498760192</td>\n",
       "      <td>919140988712724352</td>\n",
       "      <td>{\"interest_rate\": 3, \"repayment_period_in_mont...</td>\n",
       "      <td>{\"reason\": \"Unexpected expenses\", \"new_schedul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189098082925672288</td>\n",
       "      <td>535611310051475456</td>\n",
       "      <td>{\"interest_rate\": 4, \"repayment_period_in_mont...</td>\n",
       "      <td>{\"reason\": \"Unexpected expenses\", \"new_schedul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>477779993814011008</td>\n",
       "      <td>863687840789048960</td>\n",
       "      <td>{\"interest_rate\": 4, \"repayment_period_in_mont...</td>\n",
       "      <td>{\"reason\": \"Interest rate reduction\", \"new_sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>620276799861859456</td>\n",
       "      <td>375253958161880512</td>\n",
       "      <td>{\"interest_rate\": 4, \"repayment_period_in_mont...</td>\n",
       "      <td>{\"reason\": \"Interest rate reduction\", \"new_sch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     restructuring_id             loan_id  \\\n",
       "0  445645329959805120  663194010682136064   \n",
       "1  618227701498760192  919140988712724352   \n",
       "2  189098082925672288  535611310051475456   \n",
       "3  477779993814011008  863687840789048960   \n",
       "4  620276799861859456  375253958161880512   \n",
       "\n",
       "                                      new_loan_terms  \\\n",
       "0  {\"interest_rate\": 5, \"repayment_period_in_mont...   \n",
       "1  {\"interest_rate\": 3, \"repayment_period_in_mont...   \n",
       "2  {\"interest_rate\": 4, \"repayment_period_in_mont...   \n",
       "3  {\"interest_rate\": 4, \"repayment_period_in_mont...   \n",
       "4  {\"interest_rate\": 4, \"repayment_period_in_mont...   \n",
       "\n",
       "                                   restructure_terms  \n",
       "0  {\"reason\": \"Financial difficulties\", \"new_sche...  \n",
       "1  {\"reason\": \"Unexpected expenses\", \"new_schedul...  \n",
       "2  {\"reason\": \"Unexpected expenses\", \"new_schedul...  \n",
       "3  {\"reason\": \"Interest rate reduction\", \"new_sch...  \n",
       "4  {\"reason\": \"Interest rate reduction\", \"new_sch...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
